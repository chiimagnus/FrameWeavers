import cv2
import os
import numpy as np
from typing import List, Dict
import time
from datetime import datetime
import asyncio
import aiohttp
import json
import base64

class DiversityFrameExtractor:
    """
    æ™ºèƒ½è§†é¢‘æŠ½å¸§å™¨ - è‡ªé€‚åº”å‡åŒ€æŠ½å¸§ç®—æ³•
    
    è¿™ä¸ªç±»å®ç°äº†æ™ºèƒ½è§†é¢‘æŠ½å¸§åŠŸèƒ½ï¼Œä½œä¸ºè¿ç¯ç”»ç”Ÿæˆç³»ç»Ÿçš„åŸºç¡€ç»„ä»¶ã€‚
    æ ¹æ®è§†é¢‘çš„æ—¶é•¿ã€å¸§ç‡ç­‰ç‰¹æ€§è‡ªåŠ¨è®¡ç®—æœ€ä¼˜æŠ½å¸§æ•°é‡ï¼Œç¡®ä¿æ—¶é—´åˆ†å¸ƒçš„å‡åŒ€æ€§ã€‚
    """
    
    def __init__(self, output_dir: str = "diversity_frames"):
        """
        åˆå§‹åŒ–æŠ½å¸§å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œç”¨äºä¿å­˜æå–çš„å¸§
        """
        self.output_dir = output_dir
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸å­˜åœ¨çš„è¯
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"âœ“ æŠ½å¸§å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºç›®å½•ï¼š{self.output_dir}")
    
    def get_video_info(self, video_path: str) -> Dict[str, any]:
        """
        è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«è§†é¢‘ä¿¡æ¯çš„å­—å…¸
        """
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼š{video_path}")
        
        # ä½¿ç”¨OpenCVæ‰“å¼€è§†é¢‘
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼š{video_path}")
        
        # è·å–è§†é¢‘å±æ€§
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # æ€»å¸§æ•°
        fps = cap.get(cv2.CAP_PROP_FPS)                       # å¸§ç‡ï¼ˆæ¯ç§’å¸§æ•°ï¼‰
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))        # è§†é¢‘å®½åº¦
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))      # è§†é¢‘é«˜åº¦
        duration = total_frames / fps                          # è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        
        # é‡Šæ”¾è§†é¢‘èµ„æº
        cap.release()
        
        video_info = {
            'file_path': video_path,
            'file_name': os.path.basename(video_path),
            'total_frames': total_frames,
            'fps': fps,
            'width': width,
            'height': height,
            'duration_seconds': duration,
            'resolution': f"{width}x{height}"
        }
        
        return video_info
    
    def _calculate_optimal_frame_count(self, duration: float, fps: float, total_frames: int, 
                                     target_interval_seconds: float = 1.0) -> int:
        """
        æ ¹æ®è§†é¢‘ç‰¹æ€§æ™ºèƒ½è®¡ç®—æœ€ä¼˜å¸§æ•°
        
        ç®—æ³•é€»è¾‘ï¼š
        1. åŸºäºæ—¶é•¿çš„åŠ¨æ€ç­–ç•¥
        2. è€ƒè™‘å¸§ç‡çš„å½±å“
        3. è®¾ç½®åˆç†çš„ä¸Šä¸‹é™
        
        Args:
            duration: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
            fps: å¸§ç‡
            total_frames: æ€»å¸§æ•°
            target_interval_seconds: ç›®æ ‡æ—¶é—´é—´éš”
            
        Returns:
            è®¡ç®—å‡ºçš„æœ€ä¼˜å¸§æ•°
        """
        # åŸºç¡€ç­–ç•¥ï¼šæ ¹æ®æ—¶é—´é—´éš”è®¡ç®—
        base_frame_count = int(duration / target_interval_seconds)
        
        # åŠ¨æ€è°ƒæ•´ç­–ç•¥
        if duration <= 5:
            # è¶…çŸ­è§†é¢‘ï¼šæ¯0.5ç§’ä¸€å¸§ï¼Œç¡®ä¿è¶³å¤Ÿç»†èŠ‚
            optimal_frames = max(6, int(duration / 0.5))
            strategy = "è¶…çŸ­è§†é¢‘å¯†é›†é‡‡æ ·"
        elif duration <= 15:
            # çŸ­è§†é¢‘ï¼šæ¯1ç§’ä¸€å¸§
            optimal_frames = max(8, int(duration / 1.0))
            strategy = "çŸ­è§†é¢‘æ ‡å‡†é‡‡æ ·"
        elif duration <= 60:
            # ä¸­ç­‰è§†é¢‘ï¼šæ¯1-1.5ç§’ä¸€å¸§
            optimal_frames = max(12, int(duration / 1.2))
            strategy = "ä¸­ç­‰è§†é¢‘å‡è¡¡é‡‡æ ·"
        elif duration <= 180:
            # é•¿è§†é¢‘ï¼šæ¯2ç§’ä¸€å¸§
            optimal_frames = max(20, int(duration / 2.0))
            strategy = "é•¿è§†é¢‘ç¨€ç–é‡‡æ ·"
        else:
            # è¶…é•¿è§†é¢‘ï¼šæ¯3ç§’ä¸€å¸§ï¼Œä½†è®¾ç½®ä¸Šé™
            optimal_frames = min(60, max(30, int(duration / 3.0)))
            strategy = "è¶…é•¿è§†é¢‘é™åˆ¶é‡‡æ ·"
        
        # å¸§ç‡ä¿®æ­£ï¼šå¦‚æœå¸§ç‡å¾ˆä½ï¼Œé€‚å½“å‡å°‘å¸§æ•°
        if fps < 15:
            optimal_frames = int(optimal_frames * 0.8)
            strategy += " + ä½å¸§ç‡ä¿®æ­£"
        elif fps > 60:
            optimal_frames = int(optimal_frames * 1.1)
            strategy += " + é«˜å¸§ç‡ä¿®æ­£"
        
        # è®¾ç½®ç»å¯¹è¾¹ç•Œ
        optimal_frames = max(5, min(100, optimal_frames))
        
        print(f"ğŸ§  æ™ºèƒ½è®¡ç®—è¯¦æƒ…ï¼š")
        print(f"   ç­–ç•¥ï¼š{strategy}")
        print(f"   åŸºç¡€å¸§æ•°ï¼š{base_frame_count}")
        print(f"   ä¼˜åŒ–åå¸§æ•°ï¼š{optimal_frames}")
        print(f"   å®é™…é—´éš”ï¼š{duration/optimal_frames:.1f} ç§’/å¸§")
        
        return optimal_frames
    
    def generate_frame_description(self, image_path: str, frame_index: int) -> Dict[str, any]:
        """ç”Ÿæˆå¸§æè¿°å’Œè¯„åˆ†ï¼ˆä½¿ç”¨AIåˆ†æï¼‰"""
        try:
            from openai import OpenAI
            import base64
            import json
            
            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
            client = OpenAI(
                base_url="https://api.ppinfra.com/v3/openai",
                api_key="sk_5F9-39FKSyVcakGuymqzg6J8rCHfqgnp8GDfp1vN62M"
            )
            
            # è¯»å–å¹¶ç¼–ç å›¾åƒ
            with open(image_path, "rb") as image_file:
                image_data = base64.b64encode(image_file.read()).decode('utf-8')
            
            system_content = """# è§’è‰²
                ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç”µå½±æ‘„å½±æŒ‡å¯¼å’Œæ•…äº‹åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ·±å…¥è§£è¯»å•å¼ è§†é¢‘å¸§ï¼Œæ•æ‰å…¶æ‰€æœ‰çš„è§†è§‰å’Œæƒ…æ„Ÿç»†èŠ‚ï¼Œå¹¶ä»¥å¯Œæœ‰ç”»é¢æ„Ÿçš„è¯­è¨€è¿›è¡Œæè¿°å’Œè¯„ä¼°ã€‚

                # ä»»åŠ¡
                1.  **æ·±åº¦åˆ†æç”»é¢**: å…¨é¢åˆ†æç”»é¢çš„æ„å›¾ã€å…‰çº¿ã€è‰²å½©ã€ä¸»ä½“ã€åŠ¨ä½œå’ŒèƒŒæ™¯ç¯å¢ƒã€‚
                2.  **ç”Ÿæˆè¯¦ç»†æè¿°**:
                    * åˆ›ä½œä¸€æ®µ**è¯¦ç»†ä¸”å¯Œæœ‰ç”»é¢æ„Ÿ**çš„æ–‡å­—æè¿°ã€‚è¿™æ®µæè¿°åº”è¯¥åƒå°è¯´æˆ–å‰§æœ¬ä¸­çš„åœºæ™¯æå†™ä¸€æ ·ï¼Œè®©è¯»åˆ°å®ƒçš„äººèƒ½ç«‹åˆ»åœ¨è„‘æµ·ä¸­æ„å»ºå‡ºå…·ä½“çš„å½±åƒã€‚
                    * è¯·ç¡®ä¿æè¿°ä¸­åŒ…å«ä»¥ä¸‹å…³é”®è¦ç´ ï¼š
                        * **ä¸»ä½“ (Subject):** è¯¦ç»†æè¿°äººç‰©çš„å¤–è²Œç‰¹å¾ã€è¡£ç€ã€è¡¨æƒ…å’Œå§¿æ€ã€‚
                        * **åŠ¨ä½œ (Action):** ç²¾å‡†æè¿°ä¸»ä½“æ­£åœ¨å‘ç”Ÿçš„å…·ä½“è¡Œä¸ºï¼Œä»¥åŠè¯¥è¡Œä¸ºçš„æ–¹å¼æˆ–åŠ›åº¦ã€‚
                        * **ç¯å¢ƒ (Environment):** æç»˜èƒŒæ™¯ç¯å¢ƒä¸­çš„é‡è¦ç»†èŠ‚ï¼ˆå¦‚ç‰©å“ã€å…‰å½±ã€å¤©æ°”ï¼‰ï¼Œä»¥è¥é€ åœºæ™¯æ°›å›´ã€‚
                        * **æƒ…ç»ªä¸æ°›å›´ (Mood & Atmosphere):** æ¸…æ™°åœ°æŒ‡å‡ºç”»é¢ä¼ è¾¾å‡ºçš„æ ¸å¿ƒæƒ…ç»ªï¼ˆå¦‚ç´§å¼ ã€å–œæ‚¦ã€æ‚¬ç–‘ã€æ‚²ä¼¤ï¼‰å’Œæ•´ä½“æ°›å›´ã€‚
                3.  **é‡åŒ–è¯„åˆ†**:
                    * **é‡è¦æ€§åˆ†æ•° (Significance Score)**: ç»¼åˆè¯„ä¼°ç”»é¢çš„æ•…äº‹ä»·å€¼ï¼Œç»™å‡ºä¸€ä¸ª 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚
                    * **ç”»é¢è´¨é‡åˆ†æ•° (Quality Score)**: è¯„ä¼°ç”»é¢çš„æŠ€æœ¯è´¨é‡ï¼ˆæ¸…æ™°åº¦ã€æ„å›¾ã€å…‰çº¿ï¼‰ï¼Œç»™å‡ºä¸€ä¸ª 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚
                4.  **ç»“æ„åŒ–è¾“å‡º**: å°†ç»“æœä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¾“å‡ºã€‚

                # è¾“å‡ºæ ¼å¼ (ä¸¥æ ¼éµå®ˆæ­¤ JSON ç»“æ„)
                {
                "frame_id": "[è¾“å…¥çš„å¸§æ ‡è¯†ç¬¦]",
                "description": "ç‰¹å†™é•œå¤´ï¼Œä¸€åèº«ç©¿çš±ç™½è¡¬è¡«çš„å¹´è½»ç”·å­åœ¨æ·±å¤œçš„åŠå…¬å®¤é‡Œï¼Œä»–çš„è„¸è¢«ç”µè„‘å±å¹•çš„è“å…‰å†·å†·åœ°ç…§äº®ã€‚ä»–åŒçœ¼åœ†çï¼Œæµéœ²å‡ºéœ‡æƒŠå’Œéš¾ä»¥ç½®ä¿¡çš„è¡¨æƒ…ï¼Œä¸€åªæ‰‹ä¸‹æ„è¯†åœ°æ‚ä½äº†å˜´ï¼Œå±å¹•ä¸Šå¤æ‚çš„è‚¡å¸‚Kçº¿å›¾å‘ˆç°å‡ºä¸€æ¡æ–­å´–å¼çš„ä¸‹è·Œæ›²çº¿ã€‚",
                "significance_score": 0.9,
                "quality_score": 0.9
                }

                # æŒ‡ç¤º
                è¯·ç°åœ¨åˆ†ææä¾›çš„å›¾åƒå¸§ï¼Œå¹¶æŒ‰ç…§ä¸Šè¿°è¦æ±‚ç”Ÿæˆ JSON è¾“å‡ºã€‚"""
            
            # æ„å»ºæ¶ˆæ¯
            messages = [
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"è¯·åˆ†æè¿™ä¸ªè§†é¢‘å¸§ (frame_id: frame_{frame_index:04d})"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_data}"
                            }
                        }
                    ]
                }
            ]
            
            # è°ƒç”¨API
            response = client.chat.completions.create(
                model="qwen/qwen2.5-vl-72b-instruct",
                messages=messages,
                max_tokens=32768,
                temperature=1,
                top_p=1,
                presence_penalty=0,
                frequency_penalty=0,
                response_format={"type": "json_object"},
                extra_body={
                    "min_p": 0,
                    "top_k": 50,
                    "repetition_penalty": 1
                }
            )
            
            # è§£æå“åº”
            result = json.loads(response.choices[0].message.content)
            return {
                'frame_id': result.get("frame_id", f"frame_{frame_index:04d}"),
                'description': result.get("description", "AIåˆ†ææš‚æ—¶ä¸å¯ç”¨"),
                'significance_score': result.get("significance_score", 0.5),
                'quality_score': result.get("quality_score", 0.5)
            }
            
        except Exception as e:
            print(f"AIåˆ†æå¤±è´¥ (frame_{frame_index:04d}): {e}")
            # é™çº§åˆ°æ¨¡æ‹Ÿè¯„åˆ†
            import random
            descriptions = [
                "å®¤å†…åœºæ™¯ï¼Œäººç‰©æ´»åŠ¨è‡ªç„¶æµç•…",
                "ç‰¹å†™é•œå¤´ï¼Œè¡¨æƒ…ç»†èŠ‚æ¸…æ™°å¯è§",
                "å…¨æ™¯è§†è§’ï¼Œç¯å¢ƒå¸ƒå±€å®Œæ•´å±•ç°",
                "äººç‰©äº’åŠ¨ï¼ŒåŠ¨ä½œè¡¨æƒ…ç”ŸåŠ¨ä¸°å¯Œ",
                "åœºæ™¯è½¬æ¢ï¼Œç”»é¢æ„å›¾å±‚æ¬¡åˆ†æ˜",
                "å…‰çº¿å˜åŒ–ï¼Œè‰²å½©å±‚æ¬¡ä¸°å¯Œè‡ªç„¶",
                "è¿‘æ™¯æ‹æ‘„ï¼Œä¸»ä½“çªå‡ºèƒŒæ™¯è™šåŒ–",
                "å¤šå…ƒç´ ç”»é¢ï¼Œä¿¡æ¯å†…å®¹ä¸°å¯Œå¤šæ ·",
                "åŠ¨æ€åœºæ™¯ï¼Œè¿åŠ¨è½¨è¿¹æ¸…æ™°å¯è¾¨",
                "é™æ€æ„å›¾ï¼Œç”»é¢å¹³è¡¡ç¾æ„Ÿçªå‡º"
            ]
            return {
                'frame_id': f"frame_{frame_index:04d}",
                'description': descriptions[frame_index % len(descriptions)],
                'significance_score': random.uniform(0.3, 0.8),
                'quality_score': random.uniform(0.4, 0.9)
            }
    
    def extract_uniform_frames(self, video_path: str, target_interval_seconds: float = 1.0) -> List[str]:
        """
        æ™ºèƒ½å‡åŒ€æŠ½å¸§æ ¸å¿ƒç®—æ³•
        
        è¿™ä¸ªæ–¹æ³•æ ¹æ®è§†é¢‘ç‰¹æ€§è‡ªåŠ¨å†³å®šæŠ½å¸§æ•°é‡ï¼Œå®ç°æ™ºèƒ½å‡åŒ€æŠ½å¸§ï¼š
        1. åˆ†æè§†é¢‘æ—¶é•¿ã€å¸§ç‡ç­‰ç‰¹æ€§
        2. è‡ªåŠ¨è®¡ç®—æœ€ä¼˜æŠ½å¸§æ•°é‡
        3. æŒ‰å›ºå®šé—´éš”é€å¸§æå–å¹¶ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            target_interval_seconds: ç›®æ ‡æ—¶é—´é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1.0ç§’/å¸§
            
        Returns:
            æå–çš„å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print(f"ğŸ¬ å¼€å§‹æ™ºèƒ½å‡åŒ€æŠ½å¸§ï¼š{os.path.basename(video_path)}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = self.get_video_info(video_path)
        total_frames = video_info['total_frames']
        fps = video_info['fps']
        duration = video_info['duration_seconds']
        
        print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯ï¼š")
        print(f"   æ€»å¸§æ•°ï¼š{total_frames} å¸§")
        print(f"   å¸§ç‡ï¼š{fps:.2f} FPS")
        print(f"   æ—¶é•¿ï¼š{duration:.2f} ç§’")
        print(f"   åˆ†è¾¨ç‡ï¼š{video_info['resolution']}")
        
        # æ™ºèƒ½è®¡ç®—ç›®æ ‡å¸§æ•°
        target_frames = self._calculate_optimal_frame_count(duration, fps, total_frames, target_interval_seconds)
        print(f"ğŸ¤– æ™ºèƒ½è‡ªåŠ¨è®¡ç®—ç›®æ ‡å¸§æ•°ï¼š{target_frames} å¸§")
        print(f"   ç›®æ ‡æ—¶é—´é—´éš”ï¼š{target_interval_seconds} ç§’/å¸§")
        
        # è®¡ç®—æŠ½å¸§é—´éš”ï¼ˆå‡åŒ€æŠ½å¸§çš„æ ¸å¿ƒï¼‰
        frame_interval = max(1, total_frames // target_frames)
        print(f"ğŸ”¢ æŠ½å¸§é—´éš”ï¼šæ¯ {frame_interval} å¸§æå–ä¸€å¸§")
        
        # é¢„ä¼°å®é™…æå–å¸§æ•°
        estimated_frames = min(target_frames, total_frames // frame_interval)
        print(f"ğŸ“ˆ é¢„è®¡æå–ï¼š{estimated_frames} å¸§")
        
        # å¼€å§‹æå–å¸§
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼š{video_path}")
        
        frame_paths = []      # å­˜å‚¨æå–çš„å¸§æ–‡ä»¶è·¯å¾„
        frame_count = 0       # å½“å‰å¤„ç†çš„å¸§è®¡æ•°
        extracted_count = 0   # å·²æå–çš„å¸§è®¡æ•°
        start_time = time.time()
        
        print(f"âš¡ å¼€å§‹æå–å¸§...")
        
        while True:
            # è¯»å–ä¸‹ä¸€å¸§
            ret, frame = cap.read()
            if not ret:  # å¦‚æœæ²¡æœ‰æ›´å¤šå¸§ï¼Œé€€å‡ºå¾ªç¯
                break
            
            # å‡åŒ€æŠ½å¸§çš„åˆ¤æ–­æ¡ä»¶ï¼šå½“å‰å¸§æ˜¯å¦ä¸ºé—´éš”å¸§
            if frame_count % frame_interval == 0:
                # ç”Ÿæˆå¸§æ–‡ä»¶åï¼ˆä½¿ç”¨å››ä½æ•°å­—ç¼–å·ï¼‰
                frame_filename = f"base_frame_{extracted_count:04d}.jpg"
                frame_path = os.path.join(self.output_dir, frame_filename)
                
                # ä¿å­˜å¸§ä¸ºå›¾ç‰‡æ–‡ä»¶
                success = cv2.imwrite(frame_path, frame)
                if success:
                    frame_paths.append(frame_path)
                    extracted_count += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯æå–5å¸§æ˜¾ç¤ºä¸€æ¬¡ï¼‰
                    if extracted_count % 5 == 0 or extracted_count == 1:
                        elapsed = time.time() - start_time
                        print(f"   æå–è¿›åº¦ï¼š{extracted_count}/{estimated_frames} å¸§ "
                              f"(è€—æ—¶ {elapsed:.1f}s)")
                else:
                    print(f"âš ï¸ è­¦å‘Šï¼šä¿å­˜å¸§å¤±è´¥ {frame_filename}")
                
                # è¾¾åˆ°ç›®æ ‡å¸§æ•°ï¼Œæå‰ç»“æŸ
                if extracted_count >= target_frames:
                    break
            
            frame_count += 1
        
        # é‡Šæ”¾èµ„æº
        cap.release()
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        total_time = time.time() - start_time
        print(f"âœ… å‡åŒ€æŠ½å¸§å®Œæˆï¼")
        print(f"   å®é™…æå–ï¼š{len(frame_paths)} å¸§")
        print(f"   æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’")
        print(f"   å¹³å‡é€Ÿåº¦ï¼š{len(frame_paths)/total_time:.1f} å¸§/ç§’")
        
        return frame_paths
    
    def analyze_frames_with_ai(self, frame_paths: List[str]) -> List[Dict[str, any]]:
        """
        ä½¿ç”¨AIåˆ†ææ‰€æœ‰åŸºç¡€å¸§
        
        Args:
            frame_paths: åŸºç¡€å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            åŒ…å«AIåˆ†æç»“æœçš„å¸§ä¿¡æ¯åˆ—è¡¨
        """
        print(f"ğŸ¤– å¼€å§‹AIåˆ†æ {len(frame_paths)} ä¸ªåŸºç¡€å¸§...")
        analyzed_frames = []
        
        for i, frame_path in enumerate(frame_paths):
            print(f"   åˆ†æè¿›åº¦ï¼š{i+1}/{len(frame_paths)} - {os.path.basename(frame_path)}")
            
            # è·å–å›¾åƒåŸºæœ¬ä¿¡æ¯
            img = cv2.imread(frame_path)
            if img is not None:
                height, width = img.shape[:2]
                file_size = os.path.getsize(frame_path)
                
                # AIåˆ†æè·å–æè¿°å’Œè¯„åˆ†
                ai_result = self.generate_frame_description(frame_path, i)
                
                frame_info = {
                    'index': i,
                    'path': frame_path,
                    'filename': os.path.basename(frame_path),
                    'width': width,
                    'height': height,
                    'file_size': file_size,
                    'ai_analysis': ai_result
                }
                analyzed_frames.append(frame_info)
        
        print(f"âœ… AIåˆ†æå®Œæˆï¼å…±åˆ†æ {len(analyzed_frames)} ä¸ªåŸºç¡€å¸§")
        return analyzed_frames
    
    async def generate_frame_description_async(self, session: aiohttp.ClientSession, 
                                               image_path: str, frame_index: int, 
                                               semaphore: asyncio.Semaphore) -> Dict[str, any]:
        """
        å¼‚æ­¥ç”Ÿæˆå¸§æè¿°å’Œè¯„åˆ†ï¼ˆä½¿ç”¨AIåˆ†æï¼‰
        
        Args:
            session: aiohttpä¼šè¯å¯¹è±¡
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            frame_index: å¸§ç´¢å¼•
            semaphore: ä¿¡å·é‡ï¼Œç”¨äºæ§åˆ¶å¹¶å‘æ•°
            
        Returns:
            åŒ…å«AIåˆ†æç»“æœçš„å­—å…¸
        """
        async with semaphore:  # æ§åˆ¶å¹¶å‘æ•°
            try:
                # è¯»å–å¹¶ç¼–ç å›¾åƒ
                with open(image_path, "rb") as image_file:
                    image_data = base64.b64encode(image_file.read()).decode('utf-8')
                
                system_content = """# è§’è‰²
                    ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç”µå½±æ‘„å½±æŒ‡å¯¼å’Œæ•…äº‹åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯æ·±å…¥è§£è¯»å•å¼ è§†é¢‘å¸§ï¼Œæ•æ‰å…¶æ‰€æœ‰çš„è§†è§‰å’Œæƒ…æ„Ÿç»†èŠ‚ï¼Œå¹¶ä»¥å¯Œæœ‰ç”»é¢æ„Ÿçš„è¯­è¨€è¿›è¡Œæè¿°å’Œè¯„ä¼°ã€‚

                    # ä»»åŠ¡
                    1.  **æ·±åº¦åˆ†æç”»é¢**: å…¨é¢åˆ†æç”»é¢çš„æ„å›¾ã€å…‰çº¿ã€è‰²å½©ã€ä¸»ä½“ã€åŠ¨ä½œå’ŒèƒŒæ™¯ç¯å¢ƒã€‚
                    2.  **ç”Ÿæˆè¯¦ç»†æè¿°**:
                        * åˆ›ä½œä¸€æ®µ**è¯¦ç»†ä¸”å¯Œæœ‰ç”»é¢æ„Ÿ**çš„æ–‡å­—æè¿°ã€‚è¿™æ®µæè¿°åº”è¯¥åƒå°è¯´æˆ–å‰§æœ¬ä¸­çš„åœºæ™¯æå†™ä¸€æ ·ï¼Œè®©è¯»åˆ°å®ƒçš„äººèƒ½ç«‹åˆ»åœ¨è„‘æµ·ä¸­æ„å»ºå‡ºå…·ä½“çš„å½±åƒã€‚
                        * è¯·ç¡®ä¿æè¿°ä¸­åŒ…å«ä»¥ä¸‹å…³é”®è¦ç´ ï¼š
                            * **ä¸»ä½“ (Subject):** è¯¦ç»†æè¿°äººç‰©çš„å¤–è²Œç‰¹å¾ã€è¡£ç€ã€è¡¨æƒ…å’Œå§¿æ€ã€‚
                            * **åŠ¨ä½œ (Action):** ç²¾å‡†æè¿°ä¸»ä½“æ­£åœ¨å‘ç”Ÿçš„å…·ä½“è¡Œä¸ºï¼Œä»¥åŠè¯¥è¡Œä¸ºçš„æ–¹å¼æˆ–åŠ›åº¦ã€‚
                            * **ç¯å¢ƒ (Environment):** æç»˜èƒŒæ™¯ç¯å¢ƒä¸­çš„é‡è¦ç»†èŠ‚ï¼ˆå¦‚ç‰©å“ã€å…‰å½±ã€å¤©æ°”ï¼‰ï¼Œä»¥è¥é€ åœºæ™¯æ°›å›´ã€‚
                            * **æƒ…ç»ªä¸æ°›å›´ (Mood & Atmosphere):** æ¸…æ™°åœ°æŒ‡å‡ºç”»é¢ä¼ è¾¾å‡ºçš„æ ¸å¿ƒæƒ…ç»ªï¼ˆå¦‚ç´§å¼ ã€å–œæ‚¦ã€æ‚¬ç–‘ã€æ‚²ä¼¤ï¼‰å’Œæ•´ä½“æ°›å›´ã€‚
                    3.  **é‡åŒ–è¯„åˆ†**:
                        * **é‡è¦æ€§åˆ†æ•° (Significance Score)**: ç»¼åˆè¯„ä¼°ç”»é¢çš„æ•…äº‹ä»·å€¼ï¼Œç»™å‡ºä¸€ä¸ª 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚
                        * **ç”»é¢è´¨é‡åˆ†æ•° (Quality Score)**: è¯„ä¼°ç”»é¢çš„æŠ€æœ¯è´¨é‡ï¼ˆæ¸…æ™°åº¦ã€æ„å›¾ã€å…‰çº¿ï¼‰ï¼Œç»™å‡ºä¸€ä¸ª 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°ã€‚
                    4.  **ç»“æ„åŒ–è¾“å‡º**: å°†ç»“æœä¸¥æ ¼æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¾“å‡ºã€‚

                    # è¾“å‡ºæ ¼å¼ (ä¸¥æ ¼éµå®ˆæ­¤ JSON ç»“æ„)
                    {
                    "frame_id": "[è¾“å…¥çš„å¸§æ ‡è¯†ç¬¦]",
                    "description": "ç‰¹å†™é•œå¤´ï¼Œä¸€åèº«ç©¿çš±ç™½è¡¬è¡«çš„å¹´è½»ç”·å­åœ¨æ·±å¤œçš„åŠå…¬å®¤é‡Œï¼Œä»–çš„è„¸è¢«ç”µè„‘å±å¹•çš„è“å…‰å†·å†·åœ°ç…§äº®ã€‚ä»–åŒçœ¼åœ†çï¼Œæµéœ²å‡ºéœ‡æƒŠå’Œéš¾ä»¥ç½®ä¿¡çš„è¡¨æƒ…ï¼Œä¸€åªæ‰‹ä¸‹æ„è¯†åœ°æ‚ä½äº†å˜´ï¼Œå±å¹•ä¸Šå¤æ‚çš„è‚¡å¸‚Kçº¿å›¾å‘ˆç°å‡ºä¸€æ¡æ–­å´–å¼çš„ä¸‹è·Œæ›²çº¿ã€‚",
                    "significance_score": 0.9,
                    "quality_score": 0.9
                    }

                    # æŒ‡ç¤º
                    è¯·ç°åœ¨åˆ†ææä¾›çš„å›¾åƒå¸§ï¼Œå¹¶æŒ‰ç…§ä¸Šè¿°è¦æ±‚ç”Ÿæˆ JSON è¾“å‡ºã€‚"""
                
                # æ„å»ºè¯·æ±‚æ•°æ®
                payload = {
                    "model": "qwen/qwen2.5-vl-72b-instruct",
                    "messages": [
                        {
                            "role": "system",
                            "content": system_content
                        },
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text",
                                    "text": f"è¯·åˆ†æè¿™ä¸ªè§†é¢‘å¸§ (frame_id: frame_{frame_index:04d})"
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{image_data}"
                                    }
                                }
                            ]
                        }
                    ],
                    "max_tokens": 32768,
                    "temperature": 1,
                    "top_p": 1,
                    "presence_penalty": 0,
                    "frequency_penalty": 0,
                    "response_format": {"type": "json_object"},
                    "extra_body": {
                        "min_p": 0,
                        "top_k": 50,
                        "repetition_penalty": 1
                    }
                }
                
                headers = {
                    "Authorization": "Bearer sk_5F9-39FKSyVcakGuymqzg6J8rCHfqgnp8GDfp1vN62M",
                    "Content-Type": "application/json"
                }
                
                # å‘é€å¼‚æ­¥è¯·æ±‚
                async with session.post(
                    "https://api.ppinfra.com/v3/openai/chat/completions",
                    json=payload,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    response_data = await response.json()
                    
                    if response.status == 200:
                        result = json.loads(response_data['choices'][0]['message']['content'])
                        return {
                            'frame_id': result.get("frame_id", f"frame_{frame_index:04d}"),
                            'description': result.get("description", "AIåˆ†ææš‚æ—¶ä¸å¯ç”¨"),
                            'significance_score': result.get("significance_score", 0.5),
                            'quality_score': result.get("quality_score", 0.5)
                        }
                    else:
                        raise Exception(f"APIè¯·æ±‚å¤±è´¥: {response.status}")
                        
            except Exception as e:
                print(f"AIåˆ†æå¤±è´¥ (frame_{frame_index:04d}): {e}")
                # é™çº§åˆ°æ¨¡æ‹Ÿè¯„åˆ†
                import random
                descriptions = [
                    "å®¤å†…åœºæ™¯ï¼Œäººç‰©æ´»åŠ¨è‡ªç„¶æµç•…",
                    "ç‰¹å†™é•œå¤´ï¼Œè¡¨æƒ…ç»†èŠ‚æ¸…æ™°å¯è§", 
                    "å…¨æ™¯è§†è§’ï¼Œç¯å¢ƒå¸ƒå±€å®Œæ•´å±•ç°",
                    "äººç‰©äº’åŠ¨ï¼ŒåŠ¨ä½œè¡¨æƒ…ç”ŸåŠ¨ä¸°å¯Œ",
                    "åœºæ™¯è½¬æ¢ï¼Œç”»é¢æ„å›¾å±‚æ¬¡åˆ†æ˜",
                    "å…‰çº¿å˜åŒ–ï¼Œè‰²å½©å±‚æ¬¡ä¸°å¯Œè‡ªç„¶",
                    "è¿‘æ™¯æ‹æ‘„ï¼Œä¸»ä½“çªå‡ºèƒŒæ™¯è™šåŒ–",
                    "å¤šå…ƒç´ ç”»é¢ï¼Œä¿¡æ¯å†…å®¹ä¸°å¯Œå¤šæ ·",
                    "åŠ¨æ€åœºæ™¯ï¼Œè¿åŠ¨è½¨è¿¹æ¸…æ™°å¯è¾¨",
                    "é™æ€æ„å›¾ï¼Œç”»é¢å¹³è¡¡ç¾æ„Ÿçªå‡º"
                ]
                return {
                    'frame_id': f"frame_{frame_index:04d}",
                    'description': descriptions[frame_index % len(descriptions)],
                    'significance_score': random.uniform(0.3, 0.8),
                    'quality_score': random.uniform(0.4, 0.9)
                }
    
    async def analyze_frames_with_ai_async(self, frame_paths: List[str], 
                                           max_concurrent: int = 50) -> List[Dict[str, any]]:
        """
        ä½¿ç”¨AIå¼‚æ­¥å¹¶å‘åˆ†ææ‰€æœ‰åŸºç¡€å¸§
        
        Args:
            frame_paths: åŸºç¡€å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            max_concurrent: æœ€å¤§å¹¶å‘æ•°ï¼ˆé»˜è®¤50ï¼‰
            
        Returns:
            åŒ…å«AIåˆ†æç»“æœçš„å¸§ä¿¡æ¯åˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹AIå¼‚æ­¥å¹¶å‘åˆ†æ {len(frame_paths)} ä¸ªåŸºç¡€å¸§...")
        print(f"ğŸ”§ å¹¶å‘è®¾ç½®ï¼šæœ€å¤§å¹¶å‘æ•° = {max_concurrent}")
        
        # åˆ›å»ºä¿¡å·é‡æ¥æ§åˆ¶å¹¶å‘æ•°
        semaphore = asyncio.Semaphore(max_concurrent)
        analyzed_frames = []
        
        # åˆ›å»ºaiohttpä¼šè¯
        connector = aiohttp.TCPConnector(limit=max_concurrent * 2)  # è¿æ¥æ± å¤§å°
        timeout = aiohttp.ClientTimeout(total=60)  # æ€»è¶…æ—¶æ—¶é—´
        
        async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
            # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
            tasks = []
            for i, frame_path in enumerate(frame_paths):
                task = self._process_frame_async(session, frame_path, i, semaphore)
                tasks.append(task)
            
            # å¯åŠ¨æ‰€æœ‰ä»»åŠ¡å¹¶æ˜¾ç¤ºè¿›åº¦
            print(f"âš¡ å¯åŠ¨ {len(tasks)} ä¸ªå¹¶å‘AIåˆ†æä»»åŠ¡...")
            start_time = time.time()
            
            # ä½¿ç”¨asyncio.gatheræ¥ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            try:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                # å¤„ç†ç»“æœ
                for i, result in enumerate(results):
                    if isinstance(result, Exception):
                        print(f"ä»»åŠ¡ {i} æ‰§è¡Œå¤±è´¥: {result}")
                    elif result is not None:
                        analyzed_frames.append(result)
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if (i + 1) % 10 == 0 or (i + 1) == len(results):
                        elapsed = time.time() - start_time
                        speed = (i + 1) / elapsed if elapsed > 0 else 0
                        print(f"   åˆ†æè¿›åº¦ï¼š{i + 1}/{len(frame_paths)} "
                              f"(é€Ÿåº¦: {speed:.1f} å¸§/ç§’)")
                        
            except Exception as e:
                print(f"æ‰¹é‡ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        
        # æŒ‰åŸå§‹ç´¢å¼•æ’åº
        analyzed_frames.sort(key=lambda x: x['index'])
        
        total_time = time.time() - start_time
        print(f"âœ… AIå¼‚æ­¥åˆ†æå®Œæˆï¼")
        print(f"   å¤„ç†å¸§æ•°ï¼š{len(analyzed_frames)} ä¸ª")
        print(f"   æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’")
        print(f"   å¹³å‡é€Ÿåº¦ï¼š{len(analyzed_frames)/total_time:.1f} å¸§/ç§’")
        print(f"   ğŸš€ ç›¸æ¯”ä¸²è¡Œå¤„ç†ï¼Œé¢„è®¡æé€Ÿ {max_concurrent//2}-{max_concurrent}x")
        
        return analyzed_frames
    
    async def _process_frame_async(self, session: aiohttp.ClientSession, 
                                   frame_path: str, frame_index: int,
                                   semaphore: asyncio.Semaphore) -> Dict[str, any]:
        """
        å¼‚æ­¥å¤„ç†å•ä¸ªå¸§çš„å®Œæ•´ä¿¡æ¯è·å–
        
        Args:
            session: aiohttpä¼šè¯
            frame_path: å¸§æ–‡ä»¶è·¯å¾„
            frame_index: å¸§ç´¢å¼•
            semaphore: ä¿¡å·é‡
            
        Returns:
            å®Œæ•´çš„å¸§ä¿¡æ¯å­—å…¸
        """
        try:
            # è·å–å›¾åƒåŸºæœ¬ä¿¡æ¯
            img = cv2.imread(frame_path)
            if img is None:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {frame_path}")
                return None
                
            height, width = img.shape[:2]
            file_size = os.path.getsize(frame_path)
            
            # AIåˆ†æè·å–æè¿°å’Œè¯„åˆ†
            ai_result = await self.generate_frame_description_async(
                session, frame_path, frame_index, semaphore
            )
            
            frame_info = {
                'index': frame_index,
                'path': frame_path,
                'filename': os.path.basename(frame_path),
                'width': width,
                'height': height,
                'file_size': file_size,
                'ai_analysis': ai_result
            }
            return frame_info
            
        except Exception as e:
            print(f"å¤„ç†å¸§å¤±è´¥ {frame_path}: {e}")
            return None
    
    def select_key_frames_by_ai(self, analyzed_frames: List[Dict[str, any]], 
                               target_key_frames: int = 10,
                               significance_weight: float = 0.6,
                               quality_weight: float = 0.4) -> List[Dict[str, any]]:
        """
        åŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§
        
        Args:
            analyzed_frames: AIåˆ†æåçš„å¸§ä¿¡æ¯åˆ—è¡¨
            target_key_frames: ç›®æ ‡å…³é”®å¸§æ•°é‡
            significance_weight: é‡è¦æ€§æƒé‡
            quality_weight: è´¨é‡æƒé‡
            
        Returns:
            ç­›é€‰å‡ºçš„å…³é”®å¸§åˆ—è¡¨
        """
        print(f"ğŸ¯ å¼€å§‹åŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§...")
        print(f"   ç›®æ ‡å…³é”®å¸§æ•°ï¼š{target_key_frames}")
        print(f"   é‡è¦æ€§æƒé‡ï¼š{significance_weight}, è´¨é‡æƒé‡ï¼š{quality_weight}")
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        for frame in analyzed_frames:
            ai_analysis = frame['ai_analysis']
            significance_score = ai_analysis['significance_score']
            quality_score = ai_analysis['quality_score']
            
            # ç»¼åˆè¯„åˆ† = é‡è¦æ€§åˆ†æ•° Ã— é‡è¦æ€§æƒé‡ + è´¨é‡åˆ†æ•° Ã— è´¨é‡æƒé‡
            combined_score = (significance_score * significance_weight + 
                            quality_score * quality_weight)
            frame['combined_score'] = combined_score
        
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼ˆé™åºï¼‰
        sorted_frames = sorted(analyzed_frames, key=lambda x: x['combined_score'], reverse=True)
        
        # é€‰æ‹©è¯„åˆ†æœ€é«˜çš„å…³é”®å¸§
        selected_frames = sorted_frames[:target_key_frames]
        
        # æŒ‰åŸå§‹æ—¶é—´é¡ºåºé‡æ–°æ’åº
        selected_frames.sort(key=lambda x: x['index'])
        
        print(f"âœ… å…³é”®å¸§ç­›é€‰å®Œæˆï¼")
        print(f"   é€‰æ‹©çš„å…³é”®å¸§è¯„åˆ†èŒƒå›´ï¼š{selected_frames[-1]['combined_score']:.3f} - {selected_frames[0]['combined_score']:.3f}")
        
        return selected_frames
    
    def save_key_frames(self, selected_frames: List[Dict[str, any]], 
                       output_prefix: str = "key_frame") -> List[str]:
        """
        ä¿å­˜ç­›é€‰å‡ºçš„å…³é”®å¸§
        
        Args:
            selected_frames: ç­›é€‰å‡ºçš„å…³é”®å¸§ä¿¡æ¯
            output_prefix: è¾“å‡ºæ–‡ä»¶åå‰ç¼€
            
        Returns:
            ä¿å­˜çš„å…³é”®å¸§æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print(f"ğŸ’¾ ä¿å­˜ {len(selected_frames)} ä¸ªå…³é”®å¸§...")
        saved_paths = []
        
        for i, frame in enumerate(selected_frames):
            # è¯»å–åŸå§‹å¸§
            img = cv2.imread(frame['path'])
            if img is not None:
                # ç”Ÿæˆå…³é”®å¸§æ–‡ä»¶å
                key_frame_filename = f"{output_prefix}_{i:02d}.jpg"
                key_frame_path = os.path.join(self.output_dir, key_frame_filename)
                
                # ä¿å­˜å…³é”®å¸§
                success = cv2.imwrite(key_frame_path, img)
                if success:
                    saved_paths.append(key_frame_path)
                    print(f"   ä¿å­˜å…³é”®å¸§ï¼š{key_frame_filename} (è¯„åˆ†: {frame['combined_score']:.3f})")
                else:
                    print(f"   âš ï¸ ä¿å­˜å¤±è´¥ï¼š{key_frame_filename}")
        
        print(f"âœ… å…³é”®å¸§ä¿å­˜å®Œæˆï¼å…±ä¿å­˜ {len(saved_paths)} ä¸ªæ–‡ä»¶")
        return saved_paths
    
    def extract_ai_key_frames(self, video_path: str, 
                             target_interval_seconds: float = 1.0,
                             target_key_frames: int = 10,
                             significance_weight: float = 0.6,
                             quality_weight: float = 0.4) -> Dict[str, any]:
        """
        ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å¸§ï¼šåŸºç¡€å¸§æå– + AIåˆ†æç­›é€‰å…³é”®å¸§
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            target_interval_seconds: åŸºç¡€æŠ½å¸§çš„ç›®æ ‡æ—¶é—´é—´éš”
            target_key_frames: æœ€ç»ˆå…³é”®å¸§æ•°é‡
            significance_weight: é‡è¦æ€§æƒé‡
            quality_weight: è´¨é‡æƒé‡
            
        Returns:
            åŒ…å«å®Œæ•´å¤„ç†ç»“æœçš„å­—å…¸
        """
        print(f"ğŸš€ å¼€å§‹ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å¸§å¤„ç†...")
        start_time = time.time()
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½å‡åŒ€æŠ½å–åŸºç¡€å¸§
        print(f"\nğŸ“– ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½å‡åŒ€æŠ½å–åŸºç¡€å¸§")
        base_frames = self.extract_uniform_frames(video_path, target_interval_seconds)
        
        # ç¬¬äºŒé˜¶æ®µï¼šAIåˆ†æåŸºç¡€å¸§
        print(f"\nğŸ¤– ç¬¬äºŒé˜¶æ®µï¼šAIåˆ†æåŸºç¡€å¸§")
        analyzed_frames = self.analyze_frames_with_ai(base_frames)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šåŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§
        print(f"\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µï¼šåŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§")
        selected_frames = self.select_key_frames_by_ai(
            analyzed_frames, target_key_frames, significance_weight, quality_weight
        )
        
        # ç¬¬å››é˜¶æ®µï¼šä¿å­˜å…³é”®å¸§
        print(f"\nğŸ’¾ ç¬¬å››é˜¶æ®µï¼šä¿å­˜å…³é”®å¸§")
        key_frame_paths = self.save_key_frames(selected_frames)
        
        # è®¡ç®—å¤„ç†ç»Ÿè®¡
        total_time = time.time() - start_time
        
        result = {
            'success': True,
            'base_frames': base_frames,
            'analyzed_frames': analyzed_frames,
            'selected_frames': selected_frames,
            'key_frame_paths': key_frame_paths,
            'processing_stats': {
                'total_processing_time': total_time,
                'base_frames_count': len(base_frames),
                'analyzed_frames_count': len(analyzed_frames),
                'key_frames_count': len(selected_frames),
                'average_significance_score': sum(f['ai_analysis']['significance_score'] for f in selected_frames) / len(selected_frames),
                'average_quality_score': sum(f['ai_analysis']['quality_score'] for f in selected_frames) / len(selected_frames),
                'average_combined_score': sum(f['combined_score'] for f in selected_frames) / len(selected_frames)
            }
        }
        
        print(f"\nğŸ‰ ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å¸§å®Œæˆï¼")
        print(f"   åŸºç¡€å¸§æ•°ï¼š{len(base_frames)} â†’ å…³é”®å¸§æ•°ï¼š{len(selected_frames)}")
        print(f"   å¹³å‡é‡è¦æ€§è¯„åˆ†ï¼š{result['processing_stats']['average_significance_score']:.3f}")
        print(f"   å¹³å‡è´¨é‡è¯„åˆ†ï¼š{result['processing_stats']['average_quality_score']:.3f}")
        print(f"   æ€»å¤„ç†æ—¶é—´ï¼š{total_time:.1f} ç§’")
        
        return result
    
    async def extract_ai_key_frames_async(self, video_path: str, 
                                          target_interval_seconds: float = 1.0,
                                          target_key_frames: int = 10,
                                          significance_weight: float = 0.6,
                                          quality_weight: float = 0.4,
                                          max_concurrent: int = 50) -> Dict[str, any]:
        """
        ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å¸§ï¼šåŸºç¡€å¸§æå– + AIå¼‚æ­¥å¹¶å‘åˆ†æç­›é€‰å…³é”®å¸§
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            target_interval_seconds: åŸºç¡€æŠ½å¸§çš„ç›®æ ‡æ—¶é—´é—´éš”
            target_key_frames: æœ€ç»ˆå…³é”®å¸§æ•°é‡
            significance_weight: é‡è¦æ€§æƒé‡
            quality_weight: è´¨é‡æƒé‡
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
            
        Returns:
            åŒ…å«å®Œæ•´å¤„ç†ç»“æœçš„å­—å…¸
        """
        print(f"ğŸš€ å¼€å§‹ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å¸§å¤„ç†ï¼ˆå¼‚æ­¥å¹¶å‘ç‰ˆæœ¬ï¼‰...")
        print(f"ğŸ”§ å¼‚æ­¥è®¾ç½®ï¼šæœ€å¤§å¹¶å‘æ•° = {max_concurrent}")
        start_time = time.time()
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½å‡åŒ€æŠ½å–åŸºç¡€å¸§ï¼ˆåŒæ­¥è¿›è¡Œï¼‰
        print(f"\nğŸ“– ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½å‡åŒ€æŠ½å–åŸºç¡€å¸§")
        base_frames = self.extract_uniform_frames(video_path, target_interval_seconds)
        
        # ç¬¬äºŒé˜¶æ®µï¼šAIå¼‚æ­¥å¹¶å‘åˆ†æåŸºç¡€å¸§
        print(f"\nğŸ¤– ç¬¬äºŒé˜¶æ®µï¼šAIå¼‚æ­¥å¹¶å‘åˆ†æåŸºç¡€å¸§")
        analyzed_frames = await self.analyze_frames_with_ai_async(base_frames, max_concurrent)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šåŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§
        print(f"\nğŸ¯ ç¬¬ä¸‰é˜¶æ®µï¼šåŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§")
        selected_frames = self.select_key_frames_by_ai(
            analyzed_frames, target_key_frames, significance_weight, quality_weight
        )
        
        # ç¬¬å››é˜¶æ®µï¼šä¿å­˜å…³é”®å¸§
        print(f"\nğŸ’¾ ç¬¬å››é˜¶æ®µï¼šä¿å­˜å…³é”®å¸§")
        key_frame_paths = self.save_key_frames(selected_frames)
        
        # è®¡ç®—å¤„ç†ç»Ÿè®¡
        total_time = time.time() - start_time
        ai_analysis_time = total_time * 0.8  # AIåˆ†æé€šå¸¸å å¤§éƒ¨åˆ†æ—¶é—´
        estimated_sync_time = len(base_frames) * 2.0  # ä¼°ç®—åŒæ­¥å¤„ç†æ—¶é—´ï¼ˆæ¯å¸§2ç§’ï¼‰
        speedup_factor = estimated_sync_time / ai_analysis_time if ai_analysis_time > 0 else 1
        
        result = {
            'success': True,
            'async_mode': True,
            'max_concurrent': max_concurrent,
            'base_frames': base_frames,
            'analyzed_frames': analyzed_frames,
            'selected_frames': selected_frames,
            'key_frame_paths': key_frame_paths,
            'processing_stats': {
                'total_processing_time': total_time,
                'estimated_sync_time': estimated_sync_time,
                'speedup_factor': speedup_factor,
                'base_frames_count': len(base_frames),
                'analyzed_frames_count': len(analyzed_frames),
                'key_frames_count': len(selected_frames),
                'average_significance_score': sum(f['ai_analysis']['significance_score'] for f in selected_frames) / len(selected_frames),
                'average_quality_score': sum(f['ai_analysis']['quality_score'] for f in selected_frames) / len(selected_frames),
                'average_combined_score': sum(f['combined_score'] for f in selected_frames) / len(selected_frames),
                'processing_speed': len(analyzed_frames) / total_time if total_time > 0 else 0
            }
        }
        
        print(f"\nğŸ‰ å¼‚æ­¥å¹¶å‘ä¸¤é˜¶æ®µæ™ºèƒ½æŠ½å¸§å®Œæˆï¼")
        print(f"   åŸºç¡€å¸§æ•°ï¼š{len(base_frames)} â†’ å…³é”®å¸§æ•°ï¼š{len(selected_frames)}")
        print(f"   å¹³å‡é‡è¦æ€§è¯„åˆ†ï¼š{result['processing_stats']['average_significance_score']:.3f}")
        print(f"   å¹³å‡è´¨é‡è¯„åˆ†ï¼š{result['processing_stats']['average_quality_score']:.3f}")
        print(f"   æ€»å¤„ç†æ—¶é—´ï¼š{total_time:.1f} ç§’")
        print(f"   å¤„ç†é€Ÿåº¦ï¼š{result['processing_stats']['processing_speed']:.1f} å¸§/ç§’")
        print(f"   ğŸš€ é¢„ä¼°æé€Ÿï¼š{speedup_factor:.1f}xï¼ˆç›¸æ¯”ä¸²è¡Œå¤„ç†ï¼‰")
        
        return result
    
    async def unified_smart_extraction_async(self, video_path: str, 
                                        target_key_frames: int = 8,
                                        base_frame_interval: float = 1.0,
                                        significance_weight: float = 0.6,
                                        quality_weight: float = 0.4,
                                        max_concurrent: int = 50) -> Dict[str, any]:
        """
        ğŸ¯ ç»Ÿä¸€æ™ºèƒ½å¤„ç†æ–¹æ³•ï¼šæ™ºèƒ½æŠ½åŸºç¡€å¸§ + å¼‚æ­¥å¹¶å‘AIåˆ†æ
        
        è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ä¸¤é˜¶æ®µå¤„ç†å·¥ä½œæµç¨‹ï¼š
        é˜¶æ®µ1: æ ¹æ®è§†é¢‘ç‰¹æ€§æ™ºèƒ½æŠ½å–åŸºç¡€å¸§
        é˜¶æ®µ2: ä½¿ç”¨å¼‚æ­¥å¹¶å‘AIåˆ†æç­›é€‰å…³é”®å¸§
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            target_key_frames: ç›®æ ‡å…³é”®å¸§æ•°é‡ (æ¨è8-12ä¸ª)
            base_frame_interval: åŸºç¡€æŠ½å¸§æ—¶é—´é—´éš”(ç§’)ï¼Œç”¨äºç¬¬ä¸€é˜¶æ®µ
            significance_weight: é‡è¦æ€§è¯„åˆ†æƒé‡ (0-1)
            quality_weight: è´¨é‡è¯„åˆ†æƒé‡ (0-1)
            max_concurrent: æœ€å¤§å¼‚æ­¥å¹¶å‘æ•°ï¼Œæ§åˆ¶AIè¯·æ±‚å¹¶å‘é‡
            
        Returns:
            åŒ…å«å®Œæ•´å¤„ç†ç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬åŸºç¡€å¸§ã€AIåˆ†æç»“æœã€å…³é”®å¸§ç­‰
        """
        print("ğŸ¯ å¯åŠ¨ç»Ÿä¸€æ™ºèƒ½å¤„ç†æ¨¡å¼")
        print("=" * 60)
        print(f"ğŸ“¹ å¤„ç†è§†é¢‘ï¼š{os.path.basename(video_path)}")
        print(f"ğŸ›ï¸ é…ç½®å‚æ•°ï¼š")
        print(f"   ç›®æ ‡å…³é”®å¸§æ•°ï¼š{target_key_frames} ä¸ª")
        print(f"   åŸºç¡€æŠ½å¸§é—´éš”ï¼š{base_frame_interval} ç§’")
        print(f"   æƒé‡é…ç½®ï¼šé‡è¦æ€§ {significance_weight:.1f} | è´¨é‡ {quality_weight:.1f}")
        print(f"   æœ€å¤§å¹¶å‘æ•°ï¼š{max_concurrent}")
        
        total_start_time = time.time()
        
        try:
            # ğŸ” é¢„å¤„ç†ï¼šè·å–è§†é¢‘ä¿¡æ¯
            print(f"\nğŸ” é˜¶æ®µ0ï¼šè§†é¢‘ä¿¡æ¯åˆ†æ")
            video_info = self.get_video_info(video_path)
            print(f"   è§†é¢‘æ—¶é•¿ï¼š{video_info['duration_seconds']:.1f} ç§’")
            print(f"   è§†é¢‘å¸§ç‡ï¼š{video_info['fps']:.1f} FPS")
            print(f"   è§†é¢‘åˆ†è¾¨ç‡ï¼š{video_info['resolution']}")
            print(f"   æ€»å¸§æ•°ï¼š{video_info['total_frames']} å¸§")
            
            # ğŸ“– é˜¶æ®µ1ï¼šæ™ºèƒ½æŠ½å–åŸºç¡€å¸§
            print(f"\nğŸ“– é˜¶æ®µ1ï¼šæ™ºèƒ½æŠ½å–åŸºç¡€å¸§")
            stage1_start = time.time()
            
            base_frames = self.extract_uniform_frames(
                video_path=video_path,
                target_interval_seconds=base_frame_interval
            )
            
            stage1_time = time.time() - stage1_start
            print(f"   âœ… åŸºç¡€å¸§æŠ½å–å®Œæˆï¼š{len(base_frames)} å¸§")
            print(f"   â±ï¸ è€—æ—¶ï¼š{stage1_time:.2f} ç§’")
            
            # æ£€æŸ¥åŸºç¡€å¸§æ•°é‡
            if len(base_frames) == 0:
                raise ValueError("æ²¡æœ‰æˆåŠŸæŠ½å–åˆ°åŸºç¡€å¸§")
            
            # ğŸ¤– é˜¶æ®µ2ï¼šå¼‚æ­¥å¹¶å‘AIåˆ†æ
            print(f"\nğŸ¤– é˜¶æ®µ2ï¼šå¼‚æ­¥å¹¶å‘AIåˆ†æåŸºç¡€å¸§")
            stage2_start = time.time()
            
            analyzed_frames = await self.analyze_frames_with_ai_async(
                base_frames, max_concurrent=max_concurrent
            )
            
            stage2_time = time.time() - stage2_start
            print(f"   âœ… AIåˆ†æå®Œæˆï¼š{len(analyzed_frames)} å¸§")
            print(f"   â±ï¸ è€—æ—¶ï¼š{stage2_time:.2f} ç§’")
            print(f"   ğŸš€ åˆ†æé€Ÿåº¦ï¼š{len(analyzed_frames) / stage2_time:.1f} å¸§/ç§’")
            
            # ğŸ¯ é˜¶æ®µ3ï¼šæ™ºèƒ½ç­›é€‰å…³é”®å¸§
            print(f"\nğŸ¯ é˜¶æ®µ3ï¼šåŸºäºAIè¯„åˆ†ç­›é€‰å…³é”®å¸§")
            stage3_start = time.time()
            
            selected_frames = self.select_key_frames_by_ai(
                analyzed_frames=analyzed_frames,
                target_key_frames=target_key_frames,
                significance_weight=significance_weight,
                quality_weight=quality_weight
            )
            
            stage3_time = time.time() - stage3_start
            print(f"   âœ… å…³é”®å¸§ç­›é€‰å®Œæˆï¼š{len(selected_frames)} å¸§")
            print(f"   â±ï¸ è€—æ—¶ï¼š{stage3_time:.2f} ç§’")
            
            # ğŸ’¾ é˜¶æ®µ4ï¼šä¿å­˜å…³é”®å¸§
            print(f"\nğŸ’¾ é˜¶æ®µ4ï¼šä¿å­˜å…³é”®å¸§åˆ°ç£ç›˜")
            stage4_start = time.time()
            
            key_frame_paths = self.save_key_frames(
                selected_frames, output_prefix="unified_key"
            )
            
            stage4_time = time.time() - stage4_start
            print(f"   âœ… å…³é”®å¸§ä¿å­˜å®Œæˆï¼š{len(key_frame_paths)} ä¸ªæ–‡ä»¶")
            print(f"   â±ï¸ è€—æ—¶ï¼š{stage4_time:.2f} ç§’")
            
            # ğŸ’¾ é˜¶æ®µ5ï¼šä¿å­˜å…³é”®å¸§ä¿¡æ¯åˆ°JSONæ–‡ä»¶
            print(f"\nğŸ’¾ é˜¶æ®µ5ï¼šä¿å­˜å…³é”®å¸§ä¿¡æ¯åˆ°JSON")
            stage5_start = time.time()
            
            json_file_path = self.save_keyframes_to_json(selected_frames, video_path)
            
            stage5_time = time.time() - stage5_start
            print(f"   âœ… JSONæ–‡ä»¶ä¿å­˜å®Œæˆï¼š{json_file_path}")
            print(f"   â±ï¸ è€—æ—¶ï¼š{stage5_time:.2f} ç§’")
            
            # ğŸ“Š ç”Ÿæˆå¤„ç†ç»Ÿè®¡
            total_time = time.time() - total_start_time
            
            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            estimated_sync_time = len(base_frames) * 2.0  # å‡è®¾åŒæ­¥å¤„ç†æ¯å¸§éœ€è¦2ç§’
            speedup_factor = estimated_sync_time / stage2_time if stage2_time > 0 else 1
            
            # è®¡ç®—è´¨é‡æŒ‡æ ‡
            significance_scores = [f['ai_analysis']['significance_score'] for f in selected_frames]
            quality_scores = [f['ai_analysis']['quality_score'] for f in selected_frames]
            combined_scores = [f['combined_score'] for f in selected_frames]
            
            processing_stats = {
                'total_processing_time': total_time,
                'stage_times': {
                    'video_analysis': 0.1,  # è§†é¢‘ä¿¡æ¯åˆ†æå¾ˆå¿«
                    'base_frame_extraction': stage1_time,
                    'ai_analysis': stage2_time,
                    'key_frame_selection': stage3_time,
                    'frame_saving': stage4_time,
                    'json_saving': stage5_time
                },
                'frame_counts': {
                    'total_video_frames': video_info['total_frames'],
                    'base_frames_extracted': len(base_frames),
                    'frames_analyzed_by_ai': len(analyzed_frames),
                    'final_key_frames': len(selected_frames)
                },
                'performance_metrics': {
                    'extraction_rate': len(base_frames) / video_info['total_frames'],
                    'selection_rate': len(selected_frames) / len(analyzed_frames),
                    'overall_compression_rate': len(selected_frames) / video_info['total_frames'],
                    'ai_analysis_speed': len(analyzed_frames) / stage2_time if stage2_time > 0 else 0,
                    'estimated_sync_time': estimated_sync_time,
                    'async_speedup_factor': speedup_factor
                },
                'quality_metrics': {
                    'average_significance_score': sum(significance_scores) / len(significance_scores),
                    'average_quality_score': sum(quality_scores) / len(quality_scores),
                    'average_combined_score': sum(combined_scores) / len(combined_scores),
                    'score_ranges': {
                        'significance_range': [min(significance_scores), max(significance_scores)],
                        'quality_range': [min(quality_scores), max(quality_scores)],
                        'combined_range': [min(combined_scores), max(combined_scores)]
                    }
                }
            }
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                'success': True,
                'processing_mode': 'unified_smart_async',
                'video_info': video_info,
                'config': {
                    'target_key_frames': target_key_frames,
                    'base_frame_interval': base_frame_interval,
                    'significance_weight': significance_weight,
                    'quality_weight': quality_weight,
                    'max_concurrent': max_concurrent
                },
                'base_frames': base_frames,
                'analyzed_frames': analyzed_frames,
                'selected_frames': selected_frames,
                'key_frame_paths': key_frame_paths,
                'json_file_path': json_file_path,
                'processing_stats': processing_stats
            }
            
            # ğŸ“‹ è¾“å‡ºå¤„ç†æ‘˜è¦
            self._print_processing_summary(result)
            
            return result
            
        except Exception as e:
            print(f"âŒ ç»Ÿä¸€æ™ºèƒ½å¤„ç†å¤±è´¥ï¼š{str(e)}")
            return {
                'success': False,
                'error': str(e),
                'processing_mode': 'unified_smart_async',
                'processing_time': time.time() - total_start_time
            }
    
    def _print_processing_summary(self, result: Dict[str, any]) -> None:
        """
        æ‰“å°å¤„ç†ç»“æœæ‘˜è¦
        
        Args:
            result: å¤„ç†ç»“æœå­—å…¸
        """
        print(f"\nğŸŠ ç»Ÿä¸€æ™ºèƒ½å¤„ç†å®Œæˆï¼")
        print("=" * 60)
        
        stats = result['processing_stats']
        
        # å¤„ç†æµç¨‹æ‘˜è¦
        print(f"ğŸ“Š å¤„ç†æµç¨‹æ‘˜è¦ï¼š")
        frame_counts = stats['frame_counts']
        print(f"   åŸå§‹è§†é¢‘å¸§æ•°ï¼š{frame_counts['total_video_frames']:,} å¸§")
        print(f"   æ™ºèƒ½æŠ½å–åŸºç¡€å¸§ï¼š{frame_counts['base_frames_extracted']} å¸§")
        print(f"   AIåˆ†æå¤„ç†å¸§ï¼š{frame_counts['frames_analyzed_by_ai']} å¸§")
        print(f"   æœ€ç»ˆå…³é”®å¸§æ•°ï¼š{frame_counts['final_key_frames']} å¸§")
        
        # æ€§èƒ½æŒ‡æ ‡
        print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡ï¼š")
        perf = stats['performance_metrics']
        print(f"   æ€»å¤„ç†æ—¶é—´ï¼š{stats['total_processing_time']:.2f} ç§’")
        print(f"   AIåˆ†æé€Ÿåº¦ï¼š{perf['ai_analysis_speed']:.1f} å¸§/ç§’")
        print(f"   å¼‚æ­¥æé€Ÿå€æ•°ï¼š{perf['async_speedup_factor']:.1f}x")
        print(f"   æ•´ä½“å‹ç¼©æ¯”ï¼š{perf['overall_compression_rate']:.1%}")
        
        # è´¨é‡æŒ‡æ ‡
        print(f"\nğŸ† è´¨é‡æŒ‡æ ‡ï¼š")
        quality = stats['quality_metrics']
        print(f"   å¹³å‡é‡è¦æ€§è¯„åˆ†ï¼š{quality['average_significance_score']:.3f}")
        print(f"   å¹³å‡è´¨é‡è¯„åˆ†ï¼š{quality['average_quality_score']:.3f}")
        print(f"   å¹³å‡ç»¼åˆè¯„åˆ†ï¼š{quality['average_combined_score']:.3f}")
        
        # è¾“å‡ºæ–‡ä»¶ä¿¡æ¯
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š")
        print(f"   ä¿å­˜ç›®å½•ï¼š{self.output_dir}")
        print(f"   å…³é”®å¸§æ–‡ä»¶æ•°ï¼š{len(result['key_frame_paths'])}")
        if 'json_file_path' in result:
            print(f"   JSONæ–‡ä»¶ï¼š{result['json_file_path']}")
        
        # å…³é”®å¸§é¢„è§ˆ
        print(f"\nğŸ¬ å…³é”®å¸§é¢„è§ˆï¼ˆå‰3ä¸ªï¼‰ï¼š")
        for i, frame in enumerate(result['selected_frames'][:3]):
            ai_analysis = frame['ai_analysis']
            print(f"   {i+1}. {frame['filename']}")
            print(f"      é‡è¦æ€§ï¼š{ai_analysis['significance_score']:.3f} | "
                  f"è´¨é‡ï¼š{ai_analysis['quality_score']:.3f} | "
                  f"ç»¼åˆï¼š{frame['combined_score']:.3f}")
            print(f"      æè¿°ï¼š{ai_analysis['description'][:60]}...")

    def save_keyframes_to_json(self, selected_frames: List[Dict], video_path: str) -> str:
        """
        ä¿å­˜å…³é”®å¸§ä¿¡æ¯åˆ°JSONæ–‡ä»¶
        
        Args:
            selected_frames: ç­›é€‰å‡ºçš„å…³é”®å¸§åˆ—è¡¨
            video_path: åŸè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºç”ŸæˆJSONæ–‡ä»¶å
            
        Returns:
            str: ç”Ÿæˆçš„JSONæ–‡ä»¶è·¯å¾„
        """
        try:
            # ç”ŸæˆJSONæ–‡ä»¶åï¼ˆåŸºäºè§†é¢‘æ–‡ä»¶åï¼‰
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            json_filename = f"{video_name}_keyframes_{timestamp}.json"
            json_file_path = os.path.join(self.output_dir, json_filename)
            
            # æ„å»ºJSONæ•°æ®ç»“æ„
            keyframes_data = {
                "video_info": {
                    "video_path": video_path,
                    "video_name": os.path.basename(video_path),
                    "processing_time": datetime.now().isoformat(),
                    "total_keyframes": len(selected_frames)
                },
                "keyframes": []
            }
            
            # å¤„ç†æ¯ä¸ªå…³é”®å¸§çš„ä¿¡æ¯
            for i, frame in enumerate(selected_frames):
                # è·å–AIåˆ†æç»“æœ
                ai_analysis = frame.get('ai_analysis', {})
                
                # æ„å»ºå…³é”®å¸§ä¿¡æ¯
                keyframe_info = {
                    "index": i + 1,
                    "filename": frame.get('filename', ''),
                    "photo_path": os.path.join(self.output_dir, frame.get('filename', '')),
                    "combined_score": round(frame.get('combined_score', 0.0), 4),
                    "significance_score": round(ai_analysis.get('significance_score', 0.0), 4),
                    "quality_score": round(ai_analysis.get('quality_score', 0.0), 4),
                    "description": ai_analysis.get('description', ''),
                    "timestamp": frame.get('timestamp', 0.0),
                    "frame_position": frame.get('frame_number', 0)
                }
                
                keyframes_data["keyframes"].append(keyframe_info)
            
            # ä¿å­˜åˆ°JSONæ–‡ä»¶
            with open(json_file_path, 'w', encoding='utf-8') as f:
                json.dump(keyframes_data, f, ensure_ascii=False, indent=2)
            
            print(f"   ğŸ’¾ JSONæ–‡ä»¶ä¿å­˜è·¯å¾„ï¼š{json_file_path}")
            print(f"   ğŸ“Š åŒ…å«å…³é”®å¸§æ•°é‡ï¼š{len(selected_frames)} ä¸ª")
            
            return json_file_path
            
        except Exception as e:
            print(f"âŒ JSONæ–‡ä»¶ä¿å­˜å¤±è´¥ï¼š{str(e)}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤è·¯å¾„ï¼Œé¿å…ç¨‹åºå´©æºƒ
            return os.path.join(self.output_dir, "keyframes_error.json")

# æ™ºèƒ½æŠ½å¸§æ¼”ç¤º
def main():
    """
    ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ™ºèƒ½è§†é¢‘æŠ½å¸§åŠŸèƒ½
    æ ¹æ®è§†é¢‘ç‰¹æ€§è‡ªåŠ¨è®¡ç®—æœ€ä¼˜æŠ½å¸§æ•°é‡
    """
    print("=== æ™ºèƒ½è§†é¢‘æŠ½å¸§ç³»ç»Ÿ ===\n")
    
    # åˆ›å»ºæŠ½å¸§å™¨å®ä¾‹
    extractor = DiversityFrameExtractor(output_dir="test_frames")
    
    # è®¾ç½®æµ‹è¯•è§†é¢‘æ–‡ä»¶
    video_file = "æµ‹è¯•.mp4"
    
    # æ£€æŸ¥æµ‹è¯•è§†é¢‘æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_file):
        print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨ï¼š{video_file}")
        print("è¯·ç¡®ä¿åœ¨å½“å‰ç›®å½•æœ‰æµ‹è¯•è§†é¢‘æ–‡ä»¶")
        return
    
    try:
        # è®©ç”¨æˆ·é€‰æ‹©å¤„ç†æ¨¡å¼
        print("ğŸ”§ é€‰æ‹©å¤„ç†æ¨¡å¼ï¼š")
        print("  1. åŸºç¡€æ™ºèƒ½æŠ½å¸§ï¼ˆå¿«é€Ÿï¼ŒåŸºäºæ—¶é—´é—´éš”ï¼‰")
        print("  2. AIæ™ºèƒ½å…³é”®å¸§ç­›é€‰ï¼ˆè¾ƒæ…¢ï¼ŒåŸºäºAIåˆ†æï¼‰")
        
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å…ˆä½¿ç”¨åŸºç¡€æ¨¡å¼ï¼Œä½†å±•ç¤ºAIåŠŸèƒ½çš„ä»£ç ç»“æ„
        mode = 2  # å¯ä»¥æ”¹ä¸ºç”¨æˆ·è¾“å…¥é€‰æ‹©
        
        if mode == 1:
            # åŸºç¡€æ™ºèƒ½æŠ½å¸§æ¨¡å¼
            print("\nğŸš€ å¼€å§‹åŸºç¡€æ™ºèƒ½è§†é¢‘æŠ½å¸§å¤„ç†...")
            extracted_frames = extractor.extract_uniform_frames(
                video_path=video_file,
                target_interval_seconds=1.0  # ç›®æ ‡æ¯ç§’ä¸€å¸§
            )
            
            # åˆ›å»ºæ™ºèƒ½æŠ½å¸§æŠ¥å‘Š
            report = extractor.create_extraction_report(
                video_path=video_file,
                frame_paths=extracted_frames,
                max_frames=len(extracted_frames)
            )
            
            # æ˜¾ç¤ºå¤„ç†ç»“æœ
            print(f"\nğŸ“Š åŸºç¡€æ™ºèƒ½æŠ½å¸§å¤„ç†ç»“æœï¼š")
            print(f"   æ™ºèƒ½æå–å¸§æ•°ï¼š{len(extracted_frames)} å¸§")
            print(f"   æ ¹æ®è§†é¢‘ç‰¹æ€§è‡ªåŠ¨ä¼˜åŒ–ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®ï¼")
            
            # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
            print(f"\nğŸ“‹ æŠ½å¸§æŠ¥å‘Šæ‘˜è¦ï¼š")
            print(f"   å¤„ç†è§†é¢‘ï¼š{report['extraction_info']['video_file']}")
            print(f"   æå–æ–¹æ³•ï¼š{report['extraction_info']['extraction_method']}")
            print(f"   æ™ºèƒ½å¸§æ•°ï¼š{report['extraction_info']['actual_extracted_frames']}")
            print(f"   å¤„ç†çŠ¶æ€ï¼š{'âœ… æˆåŠŸ' if report['success'] else 'âŒ å¤±è´¥'}")
            
            # å±•ç¤ºéƒ¨åˆ†æŠ½å¸§æ–‡ä»¶
            print(f"\nğŸ“ ç”Ÿæˆçš„æŠ½å¸§æ–‡ä»¶ï¼ˆå‰5ä¸ªï¼‰ï¼š")
            for i, frame_path in enumerate(extracted_frames[:5]):
                filename = os.path.basename(frame_path)
                print(f"   {i+1}. {filename}")
        
        elif mode == 2:
            # AIæ™ºèƒ½å…³é”®å¸§ç­›é€‰æ¨¡å¼
            print("\nğŸ¤– å¼€å§‹AIæ™ºèƒ½å…³é”®å¸§ç­›é€‰å¤„ç†...")
            
            # ä½¿ç”¨æ–°çš„AIåˆ†ææ–¹æ³•
            ai_result = extractor.extract_ai_key_frames(
                video_path=video_file,
                target_interval_seconds=1.0,  # åŸºç¡€æŠ½å¸§é—´éš”
                target_key_frames=8,          # æœ€ç»ˆå…³é”®å¸§æ•°é‡ï¼ˆç¬¦åˆéœ€æ±‚çš„8-12ä¸ªï¼‰
                significance_weight=0.6,      # é‡è¦æ€§æƒé‡60%
                quality_weight=0.4           # è´¨é‡æƒé‡40%
            )
            
            if ai_result['success']:
                stats = ai_result['processing_stats']
                key_frames = ai_result['selected_frames']
                
                # æ˜¾ç¤ºAIå¤„ç†ç»“æœ
                print(f"\nğŸ¯ AIæ™ºèƒ½å…³é”®å¸§ç­›é€‰ç»“æœï¼š")
                print(f"   åŸºç¡€å¸§æ•°ï¼š{stats['base_frames_count']} å¸§")
                print(f"   æœ€ç»ˆå…³é”®å¸§æ•°ï¼š{stats['key_frames_count']} å¸§")
                print(f"   å¹³å‡é‡è¦æ€§è¯„åˆ†ï¼š{stats['average_significance_score']:.3f}")
                print(f"   å¹³å‡è´¨é‡è¯„åˆ†ï¼š{stats['average_quality_score']:.3f}")
                print(f"   å¹³å‡ç»¼åˆè¯„åˆ†ï¼š{stats['average_combined_score']:.3f}")
                print(f"   æ€»å¤„ç†æ—¶é—´ï¼š{stats['total_processing_time']:.1f} ç§’")
                
                # å±•ç¤ºå…³é”®å¸§è¯¦æƒ…
                print(f"\nğŸ¬ AIç­›é€‰çš„å…³é”®å¸§è¯¦æƒ…ï¼š")
                for i, frame in enumerate(key_frames[:3]):  # æ˜¾ç¤ºå‰3ä¸ª
                    ai_info = frame['ai_analysis']
                    print(f"   å…³é”®å¸§{i+1}: {frame['filename']}")
                    print(f"      é‡è¦æ€§ï¼š{ai_info['significance_score']:.3f}, è´¨é‡ï¼š{ai_info['quality_score']:.3f}")
                    print(f"      æè¿°ï¼š{ai_info['description'][:50]}...")
                    
        # æç¤ºå¯ç”¨çš„åŠŸèƒ½
        print(f"\nğŸ”® å¯ç”¨åŠŸèƒ½ï¼š")
        print(f"   â€¢ åŸºç¡€æ™ºèƒ½æŠ½å¸§ï¼šæ ¹æ®è§†é¢‘ç‰¹æ€§è‡ªåŠ¨è®¡ç®—å¸§æ•°")
        print(f"   â€¢ AIå…³é”®å¸§ç­›é€‰ï¼šç»“åˆé‡è¦æ€§å’Œè´¨é‡è¯„åˆ†æ™ºèƒ½ç­›é€‰")
        print(f"   â€¢ ä¸¤é˜¶æ®µå¤„ç†ï¼šå…ˆå‡åŒ€æŠ½å¸§ï¼Œå†AIåˆ†æç­›é€‰")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}")

if __name__ == "__main__":
    main()
